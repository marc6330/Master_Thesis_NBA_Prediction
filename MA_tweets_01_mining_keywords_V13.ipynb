{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import necessary packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "from datetime import datetime\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Function to creating list all_tweets for a  specific keyword"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Helper Function to fetch tweets (built into create_tweet_list)\n",
    "def get_all_tweets(topic):\n",
    "\n",
    "    # Importing keys for Twitter API\n",
    "    log = pd.read_csv('C:/Users/Marc/Dropbox/06_ESCP/01_Uni/06_MA Thesis/04_Code/01_Input/twitter_input_keys.csv', sep= ';', index_col = 'Name')\n",
    "\n",
    "    # Selecting keys\n",
    "    BEARER_TOKEN = log['key']['Bearer token']\n",
    "    consumer_key = log['key']['API key']\n",
    "    consumer_secret = log['key']['API secretkey']\n",
    "    access_token = log['key']['AccessToken']\n",
    "    access_token_secret = log['key']['AccessToken Secret']\n",
    "\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "    # Define Search parameters for Tweepy\n",
    "    # Count setting\n",
    "    new_tweets = api.search(q = topic, lang = 'en', count = 100, truncated = False, tweet_mode = 'extended', result_type = 'recent')\n",
    "\n",
    "\n",
    "    # Store in JSON format\n",
    "    json_data = [t._json for t in new_tweets]\n",
    "\n",
    "    # Transform data from JSON to Pandas DF\n",
    "    df = pd.json_normalize(json_data)\n",
    "\n",
    "    # Select columns necessary for sentiment analysis\n",
    "    all_tweets = df[['id','created_at','full_text']]\n",
    "    all_tweets.head(1)\n",
    "    oldest = all_tweets.id.iloc[-1] - 1\n",
    "\n",
    "    # While loop to mine more then the 200 tweets max at once\n",
    "    while len(all_tweets) < 200:\n",
    "\n",
    "        print(f\"getting tweets before {oldest}\")\n",
    "\n",
    "        new_tweets = api.search(q = 'Lakers', lang = 'en', count = 100, truncated = False, tweet_mode = 'extended', result_type = 'recent', max_id = oldest)\n",
    "\n",
    "\n",
    "        json_data = [t._json for t in new_tweets]\n",
    "\n",
    "\n",
    "        df = pd.json_normalize(json_data)\n",
    "        df2 = df[['id','created_at','full_text']]\n",
    "\n",
    "        all_tweets = all_tweets.append(df2, ignore_index= True)\n",
    "\n",
    "        all_tweets.reset_index()\n",
    "        all_tweets\n",
    "\n",
    "        oldest = all_tweets.id.iloc[-1]\n",
    "\n",
    "    print(f'The list is {len(all_tweets)} entires long')\n",
    "    return all_tweets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Function to fetch tweet for multiple search words\n",
    "def create_tweet_list(all_tweets):\n",
    "    # looping through the words and getting the respective neewest tweets\n",
    "    tweets  = pd.DataFrame(get_all_tweets(all_tweets[0]))\n",
    "\n",
    "    for i in range(1, len(all_tweets)):\n",
    "        new = get_all_tweets(all_tweets[i])\n",
    "        new_df = pd.DataFrame(new)\n",
    "        tweets = tweets.append(new_df, ignore_index = True)\n",
    "    return tweets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# input list of tweets to clean the date format\n",
    "def clean_created_at(tweet_list):\n",
    "    # remove duplicates in case different searchword lead to the same tweets\n",
    "    tweet_list.drop_duplicates(subset = ['id'])\n",
    "    tweet_list.drop_duplicates(subset = ['full_text'])\n",
    "\n",
    "\n",
    "    # to Datetime to have +0000 in the end\n",
    "    tweet_list['created_at'] = pd.to_datetime(tweet_list['created_at'])\n",
    "\n",
    "    # Revert to string to be able to perform following action (remove +00:00 --> indicating UTC)\n",
    "    tweet_list['created_at'] = [str(x) for x in tweet_list['created_at']]\n",
    "\n",
    "    # Removing +00:00\n",
    "    tweet_list['created_at'] = [x[:len(x) - 6] for x in tweet_list['created_at']]\n",
    "\n",
    "    # Reversing to datetime format\n",
    "    tweet_list['created_at'] = pd.to_datetime(tweet_list['created_at'])\n",
    "\n",
    "    return tweet_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Current Working point\n",
    "below\n",
    "\n",
    "Create Df with all the hashtags"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Four very common search terms in relation to the teams on twitter - Dictionary created for lookup\n",
    "hashtags = {}\n",
    "hashtags['LAL'] = ['Lakers','lakers nation','lakers basketball', 'Lakers news']\n",
    "hashtags['GSW'] = ['Golden State Warriors', 'golden state warriors basketball', 'golden state warriors fan', 'warriors nation']\n",
    "hashtags['CHB'] = ['Chicago Bulls', 'bulls', 'chicago bulls nation', 'chicago bulls fan' ]\n",
    "hashtags['BOC'] = ['Boston Celtics', 'celtics', 'celtics nation', 'celtics pride']\n",
    "hashtags['MIH'] = ['heat nation','Miami Heat', 'miami heat fan', 'heat basketball' ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# key to iterate over - look up search terms in dictionary\n",
    "keys = ['LAL','GSW','MIH','BOC','CHB']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1397888542710321153\n",
      "The list is 200 entires long\n",
      "getting tweets before 1397445449242619906\n",
      "The list is 200 entires long\n",
      "getting tweets before 1397821838449733632\n",
      "The list is 200 entires long\n",
      "getting tweets before 1397704171269378047\n",
      "The list is 200 entires long\n",
      "start sleeping\n",
      "2021/05/27 14:26:08\n",
      "0\n",
      "done sleeping\n",
      "2021/05/27 14:33:38\n",
      "getting tweets before 1397891287819472900\n",
      "The list is 200 entires long\n",
      "getting tweets before 1397445449242619906\n",
      "The list is 200 entires long\n",
      "getting tweets before 1397827750958936064\n",
      "The list is 200 entires long\n",
      "getting tweets before 1397710782176002052\n",
      "The list is 200 entires long\n",
      "start sleeping\n",
      "2021/05/27 14:37:13\n",
      "0\n",
      "done sleeping\n",
      "2021/05/27 14:44:43\n",
      "getting tweets before 1397894294845931521\n",
      "The list is 200 entires long\n",
      "getting tweets before 1397445449242619906\n",
      "The list is 200 entires long\n",
      "getting tweets before 1397833455468175359\n",
      "The list is 200 entires long\n",
      "getting tweets before 1397716972314533890\n",
      "The list is 200 entires long\n",
      "start sleeping\n",
      "2021/05/27 14:48:20\n",
      "0\n",
      "done sleeping\n",
      "2021/05/27 14:55:50\n",
      "getting tweets before 1397896564413284351\n",
      "The list is 200 entires long\n",
      "getting tweets before 1397445449242619906\n",
      "The list is 200 entires long\n",
      "getting tweets before 1397833649349873664\n",
      "The list is 200 entires long\n",
      "getting tweets before 1397717656426450948\n",
      "The list is 200 entires long\n",
      "start sleeping\n",
      "2021/05/27 14:59:13\n",
      "0\n",
      "done sleeping\n",
      "2021/05/27 15:06:43\n",
      "getting tweets before 1397732575225860096\n",
      "The list is 200 entires long\n",
      "getting tweets before 1396058045608779781\n",
      "The list is 200 entires long\n",
      "getting tweets before 1395126358016135167\n",
      "getting tweets before 1395126072635650050\n",
      "The list is 296 entires long\n",
      "getting tweets before 1397667189084147713\n",
      "The list is 200 entires long\n",
      "start sleeping\n",
      "2021/05/27 15:09:49\n",
      "0\n",
      "done sleeping\n",
      "2021/05/27 15:17:19\n",
      "getting tweets before 1397732741530193922\n",
      "The list is 200 entires long\n",
      "getting tweets before 1396058045608779781\n",
      "The list is 200 entires long\n",
      "getting tweets before 1395126358016135167\n",
      "getting tweets before 1395126072635650050\n",
      "The list is 296 entires long\n",
      "getting tweets before 1397674057705955327\n",
      "The list is 200 entires long\n",
      "start sleeping\n",
      "2021/05/27 15:20:32\n",
      "0\n",
      "done sleeping\n",
      "2021/05/27 15:28:02\n"
     ]
    },
    {
     "ename": "TweepError",
     "evalue": "Twitter error response: status code = 503",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTweepError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-14-c45b6acea7a7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mj\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mhashtags\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m                 \u001B[0mtweets\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_tweet_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhashtags\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m                 \u001B[0mtweets_cleaned\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mclean_created_at\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtweets\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m                 \u001B[0mdf_temp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_excel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'C:/Users/Marc/Dropbox/06_ESCP/01_Uni/06_MA Thesis/04_Code/02_Output/02_Tweets/'\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mi\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m'/'\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mi\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m'_Tweets.xlsx'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-10-2b41726bae61>\u001B[0m in \u001B[0;36mcreate_tweet_list\u001B[1;34m(all_tweets)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mcreate_tweet_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_tweets\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[1;31m# looping through the words and getting the respective neewest tweets\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m     \u001B[0mtweets\u001B[0m  \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_all_tweets\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_tweets\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_tweets\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-9-2cd83cb9c5d5>\u001B[0m in \u001B[0;36mget_all_tweets\u001B[1;34m(topic)\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[1;31m# Define Search parameters for Tweepy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[1;31m# Count setting\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m     \u001B[0mnew_tweets\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mapi\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msearch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mq\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtopic\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlang\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'en'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcount\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m100\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtruncated\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtweet_mode\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'extended'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult_type\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'recent'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\marc\\documents\\github\\02_python\\07_ma thesis\\lib\\site-packages\\tweepy\\binder.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    251\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    252\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 253\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    254\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    255\u001B[0m             \u001B[0mmethod\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msession\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\marc\\documents\\github\\02_python\\07_ma thesis\\lib\\site-packages\\tweepy\\binder.py\u001B[0m in \u001B[0;36mexecute\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    232\u001B[0m                     \u001B[1;32mraise\u001B[0m \u001B[0mRateLimitError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merror_msg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    233\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 234\u001B[1;33m                     \u001B[1;32mraise\u001B[0m \u001B[0mTweepError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merror_msg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mapi_code\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mapi_error_code\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    235\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    236\u001B[0m             \u001B[1;31m# Parse the response payload\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTweepError\u001B[0m: Twitter error response: status code = 503"
     ]
    }
   ],
   "source": [
    "error_log = []\n",
    "c = 0\n",
    "while c <= 8:\n",
    "    for i in keys:\n",
    "        for j in hashtags[i]:\n",
    "            try:\n",
    "                tweets = create_tweet_list((hashtags[i]))\n",
    "                tweets_cleaned = clean_created_at(tweets)\n",
    "                df_temp = pd.read_excel('C:/Users/Marc/Dropbox/06_ESCP/01_Uni/06_MA Thesis/04_Code/02_Output/02_Tweets/' + i + '/' + i + '_Tweets.xlsx')\n",
    "                df_temp = df_temp.append(tweets_cleaned)\n",
    "                df_temp.to_excel('C:/Users/Marc/Dropbox/06_ESCP/01_Uni/06_MA Thesis/04_Code/02_Output/02_Tweets/' + i + '/' + i + '_Tweets.xlsx', index = False)\n",
    "                df_temp.to_excel('C:/Users/Marc/Dropbox/06_ESCP/01_Uni/06_MA Thesis/04_Code/02_Output/02_Tweets/' + i + '/01_Per Iteration/' + i + str(c) + '_Tweets_backup.xlsx', index = False)\n",
    "                print('start sleeping')\n",
    "                print(datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "                time.sleep(450)\n",
    "                print(c)\n",
    "                print('done sleeping')\n",
    "                print(datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "            except KeyError:\n",
    "\n",
    "                print(str(i) + '##########key error in ' + str(c))\n",
    "            finally:\n",
    "                pass\n",
    "    c += 1\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Timestamp is shown in UTC, not time of location of the IP (e.g. Germany which is UTC+2 (Summer Time))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}